{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6936,"status":"ok","timestamp":1702039698232,"user":{"displayName":"VisualJunction","userId":"01182767952557198855"},"user_tz":-480},"id":"-ZU7a8199fcb"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models, transforms, datasets\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, Dataset\n","import os\n","from PIL import Image\n","import zipfile"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7652,"status":"ok","timestamp":1702039707810,"user":{"displayName":"VisualJunction","userId":"01182767952557198855"},"user_tz":-480},"id":"DP72uiEC9-yQ","outputId":"87c613bf-afe2-4405-9666-c6508c6545d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1F5aAY3sl3X8otpcknJKCEGq-g0SLmZWg\n","To: /content/foto.zip\n","100% 715M/715M [00:06<00:00, 112MB/s]\n"]}],"source":["#dataset for training\n","!gdown https://drive.google.com/uc?id=1F5aAY3sl3X8otpcknJKCEGq-g0SLmZWg"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3473,"status":"ok","timestamp":1702039712929,"user":{"displayName":"VisualJunction","userId":"01182767952557198855"},"user_tz":-480},"id":"tIgG5m1V-Mf5"},"outputs":[],"source":["os.makedirs('Dataset', exist_ok=True)\n","local_zip = '/content/foto.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/content/Dataset/')\n","zip_ref.close()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":344,"status":"ok","timestamp":1702039714814,"user":{"displayName":"VisualJunction","userId":"01182767952557198855"},"user_tz":-480},"id":"WmzphmvVGGD4"},"outputs":[],"source":["# Set device (GPU if available, otherwise CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1702039722806,"user":{"displayName":"VisualJunction","userId":"01182767952557198855"},"user_tz":-480},"id":"W0SI4VDpnWF1","outputId":"728c12cf-c89d-47e7-b23b-6d2efba14dab"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data, labels, transform=None):\n","        self.data = data\n","        self.labels = labels\n","        self.transform = transform\n","        self.classes = list(set(labels))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        image_path = self.data[index]\n","        label = self.labels[index]\n","\n","        image = Image.open(image_path).convert(\"RGB\")\n","\n","        if self.transform is not None:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","dataset_path = '/content/Dataset'\n","\n","# List untuk menyimpan path ke setiap gambar dan label\n","data = []\n","labels = []\n","\n","# Membaca setiap folder dalam dataset\n","for person_folder in os.listdir(dataset_path):\n","    person_path = os.path.join(dataset_path, person_folder)\n","\n","    # Membaca setiap gambar dalam folder person\n","    for image_file in os.listdir(person_path):\n","        image_path = os.path.join(person_path, image_file)\n","\n","        # Menambahkan path gambar dan label ke list\n","        data.append(image_path)\n","        labels.append(person_folder)\n","\n","# Membagi data menjadi train (70%), validation (15%), dan test (15%)\n","train_data, temp_data, train_labels, temp_labels = train_test_split(\n","    data, labels, test_size=0.3, random_state=42, stratify=labels)\n","\n","val_data, test_data, val_labels, test_labels = train_test_split(\n","    temp_data, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels)\n","\n","# Membuat dataset dan dataloader untuk train\n","train_dataset = CustomDataset(train_data, train_labels, transform=transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(degrees=30),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","]))\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n","\n","# Membuat dataset dan dataloader untuk validation\n","val_dataset = CustomDataset(val_data, val_labels, transform=transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","]))\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n","\n","# Membuat dataset dan dataloader untuk test\n","test_dataset = CustomDataset(test_data, test_labels, transform=transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","]))\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6605,"status":"ok","timestamp":1702039741093,"user":{"displayName":"VisualJunction","userId":"01182767952557198855"},"user_tz":-480},"id":"TZGkbVu_DVRs","outputId":"3612162d-b89b-47c2-d344-e4f927881244"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:04<00:00, 119MB/s]\n"]}],"source":["# Load pre-trained VGG16 model\n","vgg = models.vgg16(pretrained=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5843,"status":"ok","timestamp":1702039749083,"user":{"displayName":"VisualJunction","userId":"01182767952557198855"},"user_tz":-480},"id":"dYHGoeAYGkrA"},"outputs":[],"source":["# Freeze convolutional layers\n","for param in vgg.features.parameters():\n","    param.requires_grad = False\n","\n","# Store unique classes in the dataset\n","num_classes = len(train_dataset.classes)\n","\n","# Modify the classifier\n","vgg.classifier[-1] = nn.Sequential(\n","    nn.Linear(vgg.classifier[-1].in_features, 512),\n","    nn.ReLU(),\n","    nn.Dropout(0.5),  # Add dropout with 50% probability\n","    nn.Linear(512, num_classes)\n",")\n","\n","# Move the model to the device\n","vgg = vgg.to(device)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":363,"status":"ok","timestamp":1702040151042,"user":{"displayName":"VisualJunction","userId":"01182767952557198855"},"user_tz":-480},"id":"hedL7jDLqrj1"},"outputs":[],"source":["# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adagrad(vgg.parameters(), lr=0.01)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":353182,"status":"ok","timestamp":1702040506330,"user":{"displayName":"VisualJunction","userId":"01182767952557198855"},"user_tz":-480},"id":"jahAWol3GvM_","outputId":"fc0b57bb-ab8b-4968-ea3f-d5d42fd41821"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10, Loss: 367.2083, Accuracy: 0.2755\n","Validation Loss: 3.2399, Validation Accuracy: 0.1587\n","Test Loss: 3.0754, Test Accuracy: 0.1746\n","Epoch 2/10, Loss: 3.4801, Accuracy: 0.2959\n","Validation Loss: 1.5290, Validation Accuracy: 0.3492\n","Test Loss: 1.5131, Test Accuracy: 0.3810\n","Epoch 3/10, Loss: 1.6923, Accuracy: 0.4082\n","Validation Loss: 0.9384, Validation Accuracy: 0.6667\n","Test Loss: 0.8676, Test Accuracy: 0.6508\n","Epoch 4/10, Loss: 1.3447, Accuracy: 0.4932\n","Validation Loss: 0.7425, Validation Accuracy: 0.7143\n","Test Loss: 0.6245, Test Accuracy: 0.7143\n","Epoch 5/10, Loss: 1.2224, Accuracy: 0.5884\n","Validation Loss: 1.4636, Validation Accuracy: 0.5238\n","Test Loss: 1.2414, Test Accuracy: 0.4921\n","Epoch 6/10, Loss: 1.1688, Accuracy: 0.6327\n","Validation Loss: 0.3735, Validation Accuracy: 0.9048\n","Test Loss: 0.3497, Test Accuracy: 0.9365\n","Epoch 7/10, Loss: 1.5134, Accuracy: 0.6633\n","Validation Loss: 0.8109, Validation Accuracy: 0.7460\n","Test Loss: 0.6152, Test Accuracy: 0.7619\n","Epoch 8/10, Loss: 1.0500, Accuracy: 0.6224\n","Validation Loss: 0.2667, Validation Accuracy: 0.9365\n","Test Loss: 0.1305, Test Accuracy: 0.9683\n","Epoch 9/10, Loss: 0.5938, Accuracy: 0.8129\n","Validation Loss: 0.1764, Validation Accuracy: 0.9524\n","Test Loss: 0.0684, Test Accuracy: 0.9841\n","Epoch 10/10, Loss: 0.6298, Accuracy: 0.8163\n","Validation Loss: 0.1127, Validation Accuracy: 0.9524\n","Test Loss: 0.0274, Test Accuracy: 0.9841\n"]}],"source":["# Lists to store losses\n","train_losses = []\n","val_losses = []\n","test_losses = []\n","\n","# Lists to store accuracies\n","train_accuracies = []\n","val_accuracies = []\n","test_accuracies = []\n","\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    vgg.train()\n","    running_loss = 0.0\n","    correct_predictions = 0\n","    total_samples = 0\n","\n","    #Training loop\n","    for inputs, labels_tuple in train_loader:\n","        inputs = inputs.to(device)\n","\n","        # Assuming labels are strings, convert them to numerical labels\n","        labels = [train_dataset.classes.index(label) for label in labels_tuple]\n","        labels = torch.tensor(labels).to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = vgg(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","        # Calculate accuracy\n","        _, predicted = torch.max(outputs, 1)\n","        total_samples += labels.size(0)\n","        correct_predictions += (predicted == labels).sum().item()\n","\n","    # Calculate average train loss and accuracy\n","    epoch_loss = running_loss / len(train_loader)\n","    epoch_accuracy = correct_predictions / total_samples\n","\n","    # Save values for plotting\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(epoch_accuracy)\n","\n","    # Print average training loss and accuracy\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n","\n","    # Validation loop\n","    vgg.eval()\n","    val_running_loss = 0.0\n","    val_correct_predictions = 0\n","    val_total_samples = 0\n","    val_predicted_labels = []\n","    true_labels = []\n","\n","    with torch.no_grad():\n","        for inputs, labels_tuple in val_loader:\n","            inputs = inputs.to(device)\n","\n","            # Assuming labels are strings, convert them to numerical labels\n","            labels = [val_dataset.classes.index(label) for label in labels_tuple]\n","            labels = torch.tensor(labels).to(device)\n","\n","            outputs = vgg(inputs)\n","            val_loss = criterion(outputs, labels)\n","            val_running_loss += val_loss.item()\n","\n","            # Calculate accuracy\n","            _, val_predicted = torch.max(outputs, 1)\n","            val_total_samples += labels.size(0)\n","            val_correct_predictions += (val_predicted == labels).sum().item()\n","\n","            # Append true labels and predicted labels\n","            true_labels.extend(labels.cpu().numpy())\n","            val_predicted_labels.extend(val_predicted.cpu().numpy())\n","\n","    # Calculate average validation loss and accuracy\n","    val_epoch_loss = val_running_loss / len(val_loader)\n","    val_epoch_accuracy = val_correct_predictions / val_total_samples\n","\n","    # Save values for plotting\n","    val_losses.append(val_epoch_loss)\n","    val_accuracies.append(val_epoch_accuracy)\n","\n","    # Print average validation loss and accuracy\n","    print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.4f}\")\n","\n","    # Test loop\n","    vgg.eval()\n","    test_running_loss = 0.0\n","    test_correct_predictions = 0\n","    test_total_samples = 0\n","    true_labels_test = []\n","    test_predicted_labels = []\n","\n","    with torch.no_grad():\n","        for inputs, labels_tuple in test_loader:\n","            inputs = inputs.to(device)\n","\n","            # Assuming labels are strings, convert them to numerical labels\n","            labels = [test_dataset.classes.index(label) for label in labels_tuple]\n","            labels = torch.tensor(labels).to(device)\n","\n","            outputs = vgg(inputs)\n","            test_loss = criterion(outputs, labels)\n","            test_running_loss += test_loss.item()\n","\n","            # Calculate accuracy\n","            _, test_predicted = torch.max(outputs, 1)\n","            test_total_samples += labels.size(0)\n","            test_correct_predictions += (test_predicted == labels).sum().item()\n","\n","            # Save true labels and predicted labels for each batch\n","            true_labels_test.extend(labels.cpu().numpy())\n","            test_predicted_labels.extend(test_predicted.cpu().numpy())\n","\n","    # Calculate average test loss and accuracy\n","    test_epoch_loss = test_running_loss / len(test_loader)\n","    test_epoch_accuracy = test_correct_predictions / test_total_samples\n","\n","    # Save values for plotting\n","    test_losses.append(test_epoch_loss)\n","    test_accuracies.append(test_epoch_accuracy)\n","\n","    # Print average test loss and accuracy\n","    print(f\"Test Loss: {test_epoch_loss:.4f}, Test Accuracy: {test_epoch_accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":366,"status":"ok","timestamp":1702040551818,"user":{"displayName":"VisualJunction","userId":"01182767952557198855"},"user_tz":-480},"id":"EZEodZ_v7Qna","outputId":"46034f83-60c1-4486-d5b0-a8e937bf78b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix - Test Set:\n","[[11  0  0  0  0  0]\n"," [ 0 11  0  0  0  0]\n"," [ 0  0 11  0  0  0]\n"," [ 0  0  0 10  0  0]\n"," [ 0  0  0  0  9  1]\n"," [ 0  0  0  0  0 10]]\n","Classification Report - Test Set:\n","                      precision    recall  f1-score   support\n","\n","Mitra Novitri Waruwu       1.00      1.00      1.00        11\n","        Heri Gunawan       1.00      1.00      1.00        11\n"," Muhammad Ghulamzaki       1.00      1.00      1.00        11\n","        Valentin Gea       1.00      1.00      1.00        10\n","      Edy fitriyanto       1.00      0.90      0.95        10\n","       Fanesa Dwiana       0.91      1.00      0.95        10\n","\n","            accuracy                           0.98        63\n","           macro avg       0.98      0.98      0.98        63\n","        weighted avg       0.99      0.98      0.98        63\n","\n"]}],"source":["from sklearn.metrics import confusion_matrix, classification_report\n","import numpy as np\n","\n","# Convert the lists to numpy arrays for the test set\n","true_labels_test = np.array(true_labels_test)\n","test_predicted_labels = np.array(test_predicted_labels)\n","\n","# Calculate confusion matrix for the test set\n","conf_matrix_test = confusion_matrix(true_labels_test, test_predicted_labels)\n","\n","# Print confusion matrix for the test set\n","print(\"Confusion Matrix - Test Set:\")\n","print(conf_matrix_test)\n","\n","# Calculate and print classification report for the test set\n","class_report_test = classification_report(true_labels_test, test_predicted_labels, target_names=test_dataset.classes)\n","print(\"Classification Report - Test Set:\")\n","print(class_report_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NEpAxIGqeK8k"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Plot kurva loss\n","plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n","plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n","plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')  # Tambahkan kurva loss untuk set uji\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","# Plot kurva akurasi\n","plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy')\n","plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n","plt.plot(range(1, num_epochs + 1), test_accuracies, label='Test Accuracy')  # Tambahkan kurva akurasi untuk set uji\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvsNL1sSC_H2"},"outputs":[],"source":["# Mendefinisikan path untuk menyimpan model\n","os.makedirs('train_model', exist_ok=True)\n","model_path = os.path.join('train_model', 'model.pth')\n","\n","# Menyimpan model\n","torch.save(vgg.state_dict(), model_path)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1B9KTrY7yMFlWj9rCWGFHWxt0W2_ETmQU","timestamp":1701957074400},{"file_id":"1Ki3VF1B7o11OJLHTEq-hU2wMKELTu61D","timestamp":1701066945317},{"file_id":"1NrMOhqTjwLW1AQwRG9lPXeEdVJfrIMua","timestamp":1700137447113}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
